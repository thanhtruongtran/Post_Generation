{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain tiktoken replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.1.17\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/hainh/RecSys/post-generation/venv/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_CWedkmI5gus2KcDPwch62vnipj55rVP4Qbjz8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Replicate\n",
    "from langchain import PromptTemplate, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hainh/RecSys/post-generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hainh/RecSys/post-generation/venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.embedding_models import EmbeddingModel\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "from databases.postgresql import PostgresDB\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# initialize\n",
    "embed_model = EmbeddingModel()._embed_model\n",
    "vector_store=PostgresDB().vetor_store\n",
    "\n",
    "#test\n",
    "\n",
    "\n",
    "query_str = \"trava, gpt\"\n",
    "query_embedding = embed_model.get_query_embedding(query_str)\n",
    "query_mode = \"default\"\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=5, mode=query_mode\n",
    ")\n",
    "\n",
    "query_result = vector_store.query(vector_store_query)\n",
    "tweet_simi =dict()\n",
    "for i in range(0, 5):\n",
    "    tweet_simi[f'tweet {i}']   = query_result.nodes[i].get_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Answer**\n",
      "\n",
      "**Introducing TRAVA's Latest Upgrade: GPT V2.0!**\n",
      "\n",
      "TRAVA is thrilled to announce the latest upgrade to its AI-powered chatbot, GPT V2.0! This major update brings a host of exciting new features, improvements, and enhancements that will take your TRAVA experience to the next level!\n",
      "\n",
      "**What's New in GPT V2.0?**\n",
      "\n",
      "The latest update to GPT V2.0 brings a range of exciting new features, including:\n",
      "* Improved conversation flow and coherence\n",
      "* Enhanced ability to understand and respond to user input\n",
      "* New UI design for easier navigation\n"
     ]
    }
   ],
   "source": [
    "llm = Replicate(\n",
    "    model=\"meta/meta-llama-3-8b-instruct\",\n",
    "    model_kwargs={\"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1},\n",
    ")\n",
    "prompt = f\"\"\"\n",
    "\n",
    "Please write me a twitter post with user's given keywords, using the writting style of these following tweets:\n",
    "- tweet1 with the context: {tweet_simi['tweet 0']}\n",
    "- tweet2 with the context: {tweet_simi['tweet 1']}\n",
    "- tweet3 with the context: {tweet_simi['tweet 2']}\n",
    "- tweet4 with teh context: {tweet_simi['tweet 3']}\n",
    "- tweet5 with the  context: {tweet_simi['tweet 4']}\n",
    "\n",
    "user's given keywords:\n",
    "\n",
    "{query_str}\n",
    "\n",
    "Write your answer in the commentary form:\n",
    "\n",
    "\"answer\": \\n\n",
    "\"your answer\"\n",
    "Note: your answer should have 3 main parts: announce title, main content, ending part with hashtags like these 5 above tweets\n",
    "Start!\n",
    "\"\"\"\n",
    "\n",
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
